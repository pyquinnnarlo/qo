import threading
import cv2
import speech_recognition as sr
import os
import time
import json
import face_recognition
import numpy as np
import logging
import hashlib
import subprocess
from flask import Flask, render_template, Response
from gtts import gTTS
from ctypes import *
from contextlib import contextmanager

# --- ALSA ERROR SUPPRESSION ---
ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)
def py_error_handler(filename, line, function, err, fmt):
    pass
c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)

@contextmanager
def no_alsa_errors():
    try:
        asound = cdll.LoadLibrary('libasound.so')
        asound.snd_lib_error_set_handler(c_error_handler)
        yield
        asound.snd_lib_error_set_handler(None)
    except:
        yield

# --- CONFIGURATION ---
app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

MIC_INDEX = None 

# Global Variables
video_frame = None
known_face_encodings = []
known_face_names = []
current_detected_name = None  
current_status = "SYSTEM READY"

# --- STEP 1: LOAD DATABASE ---
def load_student_data():
    print(" [DB] Loading Student Faces...")
    global known_face_encodings, known_face_names
    
    path = "student_pics"
    if not os.path.exists(path):
        os.makedirs(path)
        print(" [DB] 'student_pics' folder created. Add images there.")
        return

    for file in os.listdir(path):
        if file.endswith((".jpg", ".png", ".jpeg")):
            try:
                img = face_recognition.load_image_file(f"{path}/{file}")
                encodings = face_recognition.face_encodings(img)
                
                if len(encodings) > 0:
                    known_face_encodings.append(encodings[0])
                    # Force underscore format to match JSON keys (e.g. "Mark_Moore")
                    name = os.path.splitext(file)[0].replace(" ", "_")
                    known_face_names.append(name)
                    print(f"   + Loaded: {name}")
                else:
                    print(f"   - Warning: No face found in {file}")
            except Exception as e:
                print(f"   - Error loading {file}: {e}")
    
    print(f" [DB] System Ready. Known students: {len(known_face_names)}")

def check_registration(name):
    """
    Checks JSON for the student.
    Returns: (is_registered (bool), spoken_name (str))
    """
    try:
        json_file = 'students.json'
        
        if not os.path.exists(json_file):
            return None, name # No DB found

        with open(json_file, 'r') as f:
            try:
                db = json.load(f)
            except json.JSONDecodeError:
                print(" [ERROR] students.json is corrupt.")
                return None, name

        # 1. Normalize name to match JSON Key (Mark Moore -> Mark_Moore)
        lookup_key = name.replace(" ", "_")
        
        # 2. Look up
        student_data = db.get(lookup_key)
        
        if student_data:
            # Found! Return status and the pretty full name
            registered = student_data.get('registered', False)
            full_name = student_data.get('full_name', name.replace("_", " "))
            return registered, full_name
        else:
            # Not in JSON
            return None, name.replace("_", " ")

    except Exception as e:
        print(f" [DB ERROR] {e}")
        return None, name

# --- AUDIO FUNCTIONS ---
def update_status(status):
    global current_status
    current_status = status

def speak(text):
    global current_status
    print(f"Robot: {text}")
    
    prev_status = current_status
    update_status(f"SPEAKING: {text}")
    
    filename = hashlib.md5(text.encode()).hexdigest() + ".mp3"
    file_path = f"audio_cache/{filename}"
    
    if not os.path.exists("audio_cache"):
        os.makedirs("audio_cache")

    if not os.path.exists(file_path):
        try:
            tts = gTTS(text=text, lang='en', tld='co.uk')
            tts.save(file_path)
        except Exception as e:
            print(f" [ERROR] Could not generate TTS: {e}")
            update_status(prev_status)
            return

    subprocess.run(["mpg123", "-q", file_path])
    update_status(prev_status)

def listen_for_name():
    """Asks for name with error handling"""
    update_status("LISTENING")
    speak("Face not recognized. Please state your name.")
    
    r = sr.Recognizer()
    
    with no_alsa_errors():
        try:
            mic = sr.Microphone(device_index=MIC_INDEX)
            with mic as source:
                r.adjust_for_ambient_noise(source, duration=0.5)
                print(" [AUDIO] Listening...")
                audio = r.listen(source, timeout=4, phrase_time_limit=4)
                
                update_status("THINKING")
                name = r.recognize_sphinx(audio).lower()
                print(f" [AUDIO] Heard: {name}")
                return name
        except sr.WaitTimeoutError:
            print(" [AUDIO] Timeout.")
            return None
        except sr.UnknownValueError:
            speak("I did not understand.")
            return None
        except Exception as e:
            print(f" [AUDIO] Error: {e}")
            return None
        finally:
            update_status("IDLE")

# --- WEB SERVER ---
@app.route('/')
def index():
    return render_template('index.html')

def generate_frames():
    global video_frame
    while True:
        if video_frame is not None:
            try:
                ret, buffer = cv2.imencode('.jpg', video_frame)
                yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            except Exception as e:
                pass
        time.sleep(0.04)

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status_feed')
def status_feed():
    def generate():
