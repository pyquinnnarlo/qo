import threading
import cv2
import os
import time
import json
import face_recognition
import numpy as np
import logging
import hashlib
import subprocess
from flask import Flask, render_template, Response, request, jsonify
from gtts import gTTS

# --- CONFIGURATION ---
app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

# Global Variables
video_frame = None
frame_lock = threading.Lock() # Mutex for thread-safe frame access
known_face_encodings = []
known_face_names = []

current_detected_name = None  
current_face_location = None 
current_status = "SYSTEM READY"

# Thread Communication
pending_registration_data = None
registration_frame_buffer = None

# --- DATABASE MANAGEMENT ---
def load_student_data():
    print(" [DB] Loading Student Faces...")
    global known_face_encodings, known_face_names
    known_face_encodings = []
    known_face_names = []

    path = "student_pics"
    if not os.path.exists(path): os.makedirs(path)

    for file in os.listdir(path):
        if file.endswith((".jpg", ".png")):
            try:
                img = face_recognition.load_image_file(f"{path}/{file}")
                encs = face_recognition.face_encodings(img)
                if encs:
                    known_face_encodings.append(encs[0])
                    known_face_names.append(os.path.splitext(file)[0])
                    print(f"   + Loaded: {file}")
            except: pass

def save_new_student(name, student_id, frame):
    try:
        clean_name = name.strip().replace(" ", "_")
        img_path = f"student_pics/{clean_name}.jpg"
        
        # Save image
        cv2.imwrite(img_path, frame)

        # Update JSON
        json_file = 'students.json'
        db = {}
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r') as f:
                    content = f.read().strip()
                    if content: db = json.loads(content)
            except: db = {}

        db[clean_name] = {
            "full_name": name,
            "student_id": student_id,
            "registered": True,
            "timestamp": time.time()
        }
        
        with open(json_file, 'w') as f: json.dump(db, f, indent=4)
        
        # Update Memory
        new_enc = face_recognition.face_encodings(frame)
        if new_enc:
            known_face_encodings.append(new_enc[0])
            known_face_names.append(clean_name)
            
        return True
    except Exception as e:
        print(f" [ERROR] Save failed: {e}")
        return False

# --- UTILS ---
def get_current_frame():
    """Thread-safe way to get a copy of the current frame"""
    with frame_lock:
        if video_frame is not None:
            return video_frame.copy()
    return None

def check_lighting(frame, face_loc):
    if frame is None or face_loc is None: return False, 0
    try:
        top, right, bottom, left = face_loc
        # Ensure coordinates are within bounds
        h, w, _ = frame.shape
        top = max(0, top); left = max(0, left)
        bottom = min(h, bottom); right = min(w, right)
        
        face_roi = frame[top:bottom, left:right]
        if face_roi.size == 0: return False, 0

        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        avg_brightness = np.mean(gray)
        return avg_brightness > 60, avg_brightness # Threshold 60
    except Exception as e:
        return False, 0

def speak(text):
    global current_status
    print(f"Robot: {text}")
    filename = hashlib.md5(text.encode()).hexdigest() + ".mp3"
    file_path = f"audio_cache/{filename}"
    
    if not os.path.exists("audio_cache"): os.makedirs("audio_cache")
    if not os.path.exists(file_path):
        try:
            tts = gTTS(text=text, lang='en', tld='co.uk')
            tts.save(file_path)
        except: return

    # Using subprocess call instead of run to avoid some threading issues
    subprocess.call(["mpg123", "-q", file_path])

def update_status(status):
    global current_status
    current_status = status

# --- FLASK ---
@app.route('/')
def index(): return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    def generate():
        while True:
            # Thread-safe read for streaming
            with frame_lock:
                if video_frame is not None:
                    # Encode to JPEG (in-memory)
                    ret, buf = cv2.imencode('.jpg', video_frame)
                    if ret:
                        frame_bytes = buf.tobytes()
                    else:
                        frame_bytes = None
                else:
                    frame_bytes = None

            if frame_bytes:
                yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            
            time.sleep(0.04)
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status_feed')
def status_feed():
    def generate():
        while True:
            yield f"data: {current_status}\n\n"
            time.sleep(0.2)
    return Response(generate(), mimetype="text/event-stream")

@app.route('/register_student', methods=['POST'])
def register_student():
    global pending_registration_data
    data = request.json
    if data.get('name') and data.get('id'):
        pending_registration_data = data
        return jsonify({"status": "received"}), 200
    return jsonify({"status": "error"}), 400

# --- LOGIC LOOP ---
def logic_loop():
    global current_detected_name, pending_registration_data, registration_frame_buffer, current_face_location
    
    time.sleep(2)
    speak("System Online.")

    while True:
        update_status("WAITING FOR STUDENT")
        
        if current_detected_name is None:
            time.sleep(0.5)
            continue

        detected = current_detected_name

        # 1. KNOWN STUDENT
        if detected != "Unknown":
            update_status(f"WELCOME BACK {detected}")
            speak(f"Hello {detected.replace('_', ' ')}.")
            time.sleep(1)
            while current_detected_name is not None: time.sleep(0.5)
            continue

        # 2. NEW STUDENT
        if detected == "Unknown":
            update_status("NEW STUDENT DETECTED")
            speak("Hello. I do not recognize you.")
            time.sleep(0.5)
            
            # --- INSTRUCTIONS ---
            update_status("PREPARING FOR PHOTO")
            speak("Please look directly at the camera.")
            time.sleep(0.5)
            speak("Please remove any hats, glasses, or hair covering your face.")
            time.sleep(3) 
            
            # --- LIGHTING CHECK ---
            # Thread-safe Frame Grab
            frame_snapshot = get_current_frame()
            
            if frame_snapshot is not None and current_face_location is not None:
                is_bright, val = check_lighting(frame_snapshot, current_face_location)
                if not is_bright:
                    update_status("LIGHTING TOO DARK")
                    speak("The lighting is too dark.")
                    speak("Please step into the light or use a flashlight.")
                    time.sleep(3)
                    continue
            
            # --- CAPTURE ---
            speak("Hold still.")
            time.sleep(0.5)
            
            # Grab frame securely again
            registration_frame_buffer = get_current_frame()
            
            if registration_frame_buffer is None:
                speak("Camera error.")
                continue

            speak("Face captured.")
            
            # --- INPUT PHASE ---
            speak("Please enter your Name and ID on the screen.")
            update_status("INPUT REQUIRED")
            
            timer = 0
            while pending_registration_data is None:
                time.sleep(0.5)
                timer += 1
                if timer > 120: break
            
            if pending_registration_data:
                name = pending_registration_data['name']
                sid = pending_registration_data['id']
                
                update_status("SAVING...")
                if save_new_student(name, sid, registration_frame_buffer):
                    update_status("REGISTRATION COMPLETE")
                    speak("Registration successful. Thank you.")
                else:
                    speak("Error saving data.")
                
                pending_registration_data = None
                registration_frame_buffer = None
                
                speak("Please step aside.")
                while current_detected_name is not None: time.sleep(1)
            else:
                update_status("TIMEOUT")
                speak("Registration timed out. Resetting.")
                time.sleep(2)

# --- VISION LOOP ---
def vision_loop():
    global video_frame, current_detected_name, current_face_location
    
    # Raspberry Pi 5 / GStreamer Pipeline
    # Ensure libcamerasrc is robust
    pipelines = [
        "libcamerasrc ! video/x-raw, width=640, height=480, framerate=15/1, format=YUY2 ! videoconvert ! video/x-raw, format=BGR ! appsink drop=true max-buffers=1 sync=false",
        0
    ]
    
    cap = None
    for pipeline in pipelines:
        if isinstance(pipeline, str): cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
        else: cap = cv2.VideoCapture(pipeline) 
        if cap.isOpened(): break

    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue
            
        frame_count += 1
        
        # Detect every 5th frame
        if frame_count % 5 == 0:
            small = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)
            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)
            
            locs = face_recognition.face_locations(rgb)
            encs = face_recognition.face_encodings(rgb, locs)
            
            det_name = None
            curr_loc = None

            if locs:
                enc = encs[0]
                loc = locs[0]
                # Scale up x4
                curr_loc = (loc[0]*4, loc[1]*4, loc[2]*4, loc[3]*4)
                
                name = "Unknown"
                if known_face_encodings:
                    matches = face_recognition.compare_faces(known_face_encodings, enc, tolerance=0.5)
                    dists = face_recognition.face_distance(known_face_encodings, enc)
                    if len(dists) > 0:
                        best = np.argmin(dists)
                        if matches[best]: name = known_face_names[best]
                
                det_name = name

            current_detected_name = det_name
            current_face_location = curr_loc

            # Visuals
            if curr_loc:
                top, right, bottom, left = curr_loc
                color = (0, 255, 0) if det_name != "Unknown" else (0, 0, 255)
                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
                cv2.putText(frame, str(det_name), (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        # Thread-safe update
        with frame_lock:
            video_frame = frame.copy() # Explicit copy to separate from GStreamer buffer

if __name__ == "__main__":
    load_student_data()
    threading.Thread(target=vision_loop, daemon=True).start()
    threading.Thread(target=logic_loop, daemon=True).start()
    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)
