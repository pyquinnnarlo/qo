import threading
import cv2
import os
import time
import json
import face_recognition
import numpy as np
import logging
import hashlib
import subprocess
from flask import Flask, render_template, Response, request, jsonify
from gtts import gTTS

# --- CONFIGURATION ---
app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

# Global Variables
video_frame = None
known_face_encodings = []
known_face_names = []
current_detected_name = None  
current_status = "SYSTEM READY"

# Thread Communication
pending_name_input = None
registration_frame_buffer = None

# --- DATABASE MANAGEMENT ---
def load_student_data():
    print(" [DB] Loading Student Faces...")
    global known_face_encodings, known_face_names
    
    known_face_encodings = []
    known_face_names = []

    path = "student_pics"
    if not os.path.exists(path):
        os.makedirs(path)

    for file in os.listdir(path):
        if file.endswith((".jpg", ".png", ".jpeg")):
            try:
                img = face_recognition.load_image_file(f"{path}/{file}")
                encodings = face_recognition.face_encodings(img)
                if len(encodings) > 0:
                    known_face_encodings.append(encodings[0])
                    name = os.path.splitext(file)[0].replace("_", " ")
                    known_face_names.append(name)
                    print(f"   + Loaded: {name}")
            except Exception:
                pass
    print(f" [DB] Loaded {len(known_face_names)} students.")

def save_new_student(name, frame):
    """
    Saves the student image and updates students.json.
    Includes error handling for corrupt JSON files.
    """
    try:
        clean_name = name.strip().replace(" ", "_")
        
        # 1. Save Image
        img_path = f"student_pics/{clean_name}.jpg"
        cv2.imwrite(img_path, frame)
        print(f" [SAVE] Saved {img_path}")

        # 2. Update JSON (Robust Mode)
        json_file = 'students.json'
        db = {}
        
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r') as f:
                    content = f.read().strip()
                    if content:
                        db = json.loads(content)
            except json.JSONDecodeError as e:
                print(f" [WARN] students.json was corrupt ({e}). Creating a new one.")
                # We start with an empty db, effectively resetting the file
                db = {} 

        # Add new student data
        db[clean_name] = {
            "registered": True,
            "timestamp": time.time(),
            "full_name": name
        }
        
        with open(json_file, 'w') as f:
            json.dump(db, f, indent=4)
            
        # 3. Update Memory (So we recognize them immediately)
        new_encoding = face_recognition.face_encodings(frame)
        if len(new_encoding) > 0:
            known_face_encodings.append(new_encoding[0])
            known_face_names.append(name) 
            
        return True
    except Exception as e:
        print(f" [ERROR] Save failed: {e}")
        return False

# --- AUDIO OUT ---
def update_status(status):
    global current_status
    current_status = status

def speak(text):
    global current_status
    print(f"Robot: {text}")
    filename = hashlib.md5(text.encode()).hexdigest() + ".mp3"
    file_path = f"audio_cache/{filename}"
    
    if not os.path.exists("audio_cache"): os.makedirs("audio_cache")
    if not os.path.exists(file_path):
        try:
            tts = gTTS(text=text, lang='en', tld='co.uk')
            tts.save(file_path)
        except: return

    subprocess.run(["mpg123", "-q", file_path])

# --- FLASK ROUTES ---
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    def generate():
        while True:
            if video_frame is not None:
                ret, buffer = cv2.imencode('.jpg', video_frame)
                yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            time.sleep(0.04)
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status_feed')
def status_feed():
    def generate():
        while True:
            yield f"data: {current_status}\n\n"
            time.sleep(0.2)
    return Response(generate(), mimetype="text/event-stream")

@app.route('/register_student', methods=['POST'])
def register_student():
    global pending_name_input
    data = request.json
    name = data.get('name')
    if name:
        print(f" [WEB] Received Name: {name}")
        pending_name_input = name
        return jsonify({"status": "received"}), 200
    return jsonify({"status": "error"}), 400

# --- LOGIC LOOP ---
def logic_loop():
    global current_detected_name, pending_name_input, registration_frame_buffer
    
    time.sleep(2)
    speak("System Online.")

    while True:
        update_status("WAITING FOR STUDENT")
        
        # 1. Wait for Face
        if current_detected_name is None:
            time.sleep(0.5)
            continue

        detected = current_detected_name

        # 2. Existing Student
        if detected != "Unknown":
            update_status(f"HELLO {detected}")
            speak(f"Welcome back, {detected}.")
            time.sleep(2)
            while current_detected_name is not None: time.sleep(0.5)
            continue

        # 3. New Student
        if detected == "Unknown":
            update_status("NEW FACE DETECTED")
            speak("Hello. I do not recognize you.")
            time.sleep(0.5)
            
            # Freeze the frame
            if video_frame is not None:
                registration_frame_buffer = video_frame.copy()
            else:
                continue

            speak("Please type your name on the screen.")
            update_status("INPUT REQUIRED") 
            
            # Wait for Web Input
            timeout_counter = 0
            while pending_name_input is None:
                time.sleep(0.5)
                timeout_counter += 1
                if timeout_counter > 60: # 30 seconds timeout
                    break
            
            if pending_name_input:
                name = pending_name_input
                update_status("SAVING DATA...")
                
                success = save_new_student(name, registration_frame_buffer)
                
                if success:
                    update_status(f"REGISTERED: {name}")
                    speak(f"Thank you {name}. Registration complete.")
                else:
                    speak("Error saving data.")
                
                pending_name_input = None
                registration_frame_buffer = None
                
                speak("Please step aside.")
                while current_detected_name is not None: time.sleep(1)
            else:
                update_status("TIMEOUT")
                speak("Registration timed out.")
                time.sleep(2)

# --- VISION LOOP ---
def vision_loop():
    global video_frame, current_detected_name
    
    # Pi Camera / GStreamer Pipeline
    pipelines = [
        "libcamerasrc ! video/x-raw, width=640, height=480, framerate=15/1, format=YUY2 ! videoconvert ! video/x-raw, format=BGR ! appsink drop=true max-buffers=1 sync=false",
        0
    ]
    
    cap = None
    for pipeline in pipelines:
        if isinstance(pipeline, str):
            cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
        else:
            cap = cv2.VideoCapture(pipeline) 
        if cap.isOpened(): break
            
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue
            
        frame_count += 1
        
        if frame_count % 5 == 0: 
            small = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)
            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)
            
            locs = face_recognition.face_locations(rgb)
            encs = face_recognition.face_encodings(rgb, locs)
            
            names = []
            det_name = None

            for enc in encs:
                name = "Unknown"
                if known_face_encodings:
                    matches = face_recognition.compare_faces(known_face_encodings, enc, tolerance=0.5)
                    dists = face_recognition.face_distance(known_face_encodings, enc)
                    if len(dists) > 0:
                        best = np.argmin(dists)
                        if matches[best]: name = known_face_names[best]
                names.append(name)
                det_name = name
            
            current_detected_name = det_name
            
            for (top, right, bottom, left), name in zip(locs, names):
                top*=4; right*=4; bottom*=4; left*=4
                cv2.rectangle(frame, (left, top), (right, bottom), (0,255,0), 2)
                cv2.putText(frame, name, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

        video_frame = frame

if __name__ == "__main__":
    load_student_data()
    threading.Thread(target=vision_loop, daemon=True).start()
    threading.Thread(target=logic_loop, daemon=True).start()
    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)
