import threading
import cv2
import speech_recognition as sr
import os
import time
import json
import face_recognition
import numpy as np
import logging
from flask import Flask, render_template, Response

# --- CONFIGURATION ---
app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

MIC_INDEX = 1  # Your USB Mic Index

# Global Variables
video_frame = None
known_face_encodings = []
known_face_names = []
current_detected_name = None  # None = No face, "Unknown" = Face but not recognized, "Name" = Recognized
current_status = "SYSTEM READY" # For the web UI (IDLE, SPEAKING, LISTENING)

# --- STEP 1: LOAD DATABASE & FACES ---
def load_student_data():
    print(" [DB] Loading Student Faces...")
    global known_face_encodings, known_face_names
    
    path = "student_pics"
    if not os.path.exists(path):
        os.makedirs(path)
        print(" ! Created folder 'student_pics'. Please put .jpg files there!")
        return

    for file in os.listdir(path):
        if file.endswith(".jpg") or file.endswith(".png") or file.endswith(".jpeg"):
            img = face_recognition.load_image_file(f"{path}/{file}")
            encoding = face_recognition.face_encodings(img)
            
            if len(encoding) > 0:
                known_face_encodings.append(encoding[0])
                name = os.path.splitext(file)[0]
                known_face_names.append(name)
                print(f"   + Loaded: {name}")
    
    print(f" [DB] System Ready. Known students: {len(known_face_names)}")

def check_registration(name):
    """Checks JSON to see if student is registered"""
    try:
        with open('students.json', 'r') as f:
            db = json.load(f)
        student = db.get(name)
        if student:
            return student.get('registered', False)
        return None 
    except:
        return None

# --- AUDIO FUNCTIONS ---
def update_status(status):
    """Updates the global status for the Web UI"""
    global current_status
    current_status = status

def speak(text):
    """Speaks text and updates Web UI animation"""
    global current_status
    print(f"Robot: {text}")
    
    # Update UI to 'SPEAKING' so mouth moves
    prev_status = current_status
    update_status(f"SPEAKING: {text}")
    
    safe_text = text.replace("'", "").replace('"', "")
    os.system(f'espeak -ven+m3 -s160 "{safe_text}" 2>/dev/null')
    
    # Return to previous state (usually IDLE)
    update_status(prev_status)

def listen_for_name():
    """Asks for name if face is not recognized"""
    update_status("LISTENING")
    speak("Face not recognized. Please state your name clearly.")
    
    r = sr.Recognizer()
    mic = sr.Microphone(device_index=MIC_INDEX)
    
    with mic as source:
        r.adjust_for_ambient_noise(source, duration=1)
        try:
            audio = r.listen(source, timeout=5)
            name = r.recognize_google(audio).lower()
            update_status("THINKING")
            return name
        except:
            update_status("IDLE")
            return None

# --- WEB SERVER ---
@app.route('/')
def index():
    return render_template('index.html')

def generate_frames():
    global video_frame
    while True:
        if video_frame is not None:
            ret, buffer = cv2.imencode('.jpg', video_frame)
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
        time.sleep(0.04)

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status_feed')
def status_feed():
    """Server-Sent Event to update the robot face on the browser"""
    def generate():
        while True:
            yield f"data: {current_status}\n\n"
            time.sleep(0.5)
    return Response(generate(), mimetype="text/event-stream")

# --- LOGIC LOOP (THE BRAIN) ---
def exam_logic_loop():
    global current_detected_name, current_status
    
    # Initial Prompt
    time.sleep(3) # Wait for camera to warm up
    speak("System Online.")
    
    while True:
        update_status("WAITING FOR FACE")
        
        # 1. Wait until a face is detected
        if current_detected_name is None:
            speak("Please look at the camera to scan your face.")
            
            # Wait loop: Check every 1 second if a face appears
            for _ in range(10): 
                if current_detected_name is not None:
                    break
                time.sleep(1)
            continue # If still no face after 10 seconds, loop back and ask again
            
        # 2. Face Detected - Process it
        name = current_detected_name
        update_status(f"PROCESSING: {name}")
        
        if name == "Unknown":
            spoken_name = listen_for_name()
            if spoken_name:
                speak(f"I heard {spoken_name}.")
                name = spoken_name.replace(" ", "_")
        
        # 3. Check Registration
        is_registered = check_registration(name)
        
        if is_registered is True:
            speak(f"Face Match Found. Hello {name}.")
            time.sleep(0.5)
            speak("You are authorized. You may write the test.")
            speak("Good luck.")
            
            # Wait for user to leave frame before scanning again
            while current_detected_name == name:
                time.sleep(1)
            speak("Next student please.")
            
        elif is_registered is False:
            speak(f"Alert. {name}, you are NOT registered for this exam.")
            while current_detected_name == name:
                time.sleep(1)
                
        elif is_registered is None:
            speak(f"User {name} not found in database.")
            time.sleep(2)
        
        # Reset detected name so we don't process the same cached value
        # current_detected_name will be updated by Vision Loop instantly if face is still there
        time.sleep(1) 

# --- VISION LOOP ---
def vision_loop():
    global video_frame, current_detected_name
    
    print(" [VISION] Starting Camera...")
    # Standard USB Camera (Change 0 to -1 or 1 if using USB webcam on Pi)
    # If using Pi Camera Module via Libcamera, use the pipeline from your previous code
    cap = cv2.VideoCapture(0) 
    
    if not cap.isOpened():
        print(" [ERROR] Camera not found.")
        return

    while True:
        ret, frame = cap.read()
        if not ret: continue
        
        # Resize for speed
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
        
        detected_name = None # Default to None if no face

        if face_encodings:
            for face_encoding in face_encodings:
                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
                name = "Unknown"

                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                if len(face_distances) > 0:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        name = known_face_names[best_match_index]
                
                detected_name = name
        
        current_detected_name = detected_name # Update global
        
        # Draw GUI
        for (top, right, bottom, left), name in zip(face_locations, [detected_name]*len(face_locations)):
            top *= 4; right *= 4; bottom *= 4; left *= 4
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(frame, str(name), (left, bottom + 20), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)

        video_frame = frame

if __name__ == "__main__":
    load_student_data()
    
    threading.Thread(target=vision_loop, daemon=True).start()
    threading.Thread(target=exam_logic_loop, daemon=True).start()
    
    app.run(host='0.0.0.0', port=5000, debug=False)
