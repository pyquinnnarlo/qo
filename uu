import threading
import cv2
import os
import time
import json
import face_recognition
import numpy as np
import logging
import hashlib
import subprocess
from flask import Flask, render_template, Response, request, jsonify
from gtts import gTTS

# ---------------- CONFIG ----------------
app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

# ---------------- GLOBAL STATE ----------------
video_frame = None
frame_lock = threading.Lock()

known_face_encodings = []
known_face_names = []

current_detected_name = None
current_face_location = None
current_face_count = 0
current_face_encoding = None

current_status = "SYSTEM READY"

scan_active = True
pending_registration_data = None
registration_frame_buffer = None

registration_in_progress = False
last_registered_time = 0
REGISTER_COOLDOWN = 10

# ---------------- DATABASE ----------------
def load_student_data():
    global known_face_encodings, known_face_names

    print("[DB] Loading students...")
    known_face_encodings.clear()
    known_face_names.clear()

    os.makedirs("student_pics", exist_ok=True)

    for file in os.listdir("student_pics"):
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            try:
                img = face_recognition.load_image_file(f"student_pics/{file}")
                encs = face_recognition.face_encodings(img)
                if encs:
                    known_face_encodings.append(encs[0])
                    known_face_names.append(os.path.splitext(file)[0])
            except:
                pass


def student_id_exists(student_id):
    if not os.path.exists("students.json"):
        return False
    try:
        with open("students.json", "r") as f:
            db = json.load(f)
        return any(s["student_id"] == student_id for s in db.values())
    except:
        return False


def face_encoding_already_registered(enc):
    if not known_face_encodings:
        return False
    matches = face_recognition.compare_faces(known_face_encodings, enc, tolerance=0.45)
    return any(matches)


def save_new_student(name, student_id, frame):
    global current_face_encoding

    try:
        clean_name = name.strip().replace(" ", "_")
        cv2.imwrite(f"student_pics/{clean_name}.jpeg", frame)

        db = {}
        if os.path.exists("students.json"):
            with open("students.json", "r") as f:
                content = f.read().strip()
                if content:
                    db = json.loads(content)

        db[clean_name] = {
            "full_name": name,
            "student_id": student_id,
            "timestamp": time.time()
        }

        with open("students.json", "w") as f:
            json.dump(db, f, indent=4)

        if current_face_encoding is not None:
            known_face_encodings.append(current_face_encoding.copy())
            known_face_names.append(clean_name)

        return True

    except Exception as e:
        print("Save error:", e)
        return False

# ---------------- UTILS ----------------
def get_current_frame():
    with frame_lock:
        if video_frame is not None:
            return video_frame.copy()
    return None


def speak(text):
    print("Robot:", text)
    os.makedirs("audio_cache", exist_ok=True)
    fname = hashlib.md5(text.encode()).hexdigest() + ".mp3"
    path = f"audio_cache/{fname}"

    if not os.path.exists(path):
        try:
            gTTS(text=text, lang="en").save(path)
        except:
            return

    try:
        subprocess.run(["mpg123", "-q", path], timeout=6)
    except:
        pass


def update_status(s):
    global current_status
    current_status = s

# ---------------- FLASK ----------------
@app.route('/')
def index():
    return render_template("register.html")


@app.route('/video_feed')
def video_feed():
    def gen():
        while True:
            with frame_lock:
                if video_frame is None:
                    continue
                ret, buf = cv2.imencode(".jpg", video_frame)
                if not ret:
                    continue
                data = buf.tobytes()

            yield b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + data + b"\r\n"
            time.sleep(0.05)

    return Response(gen(), mimetype="multipart/x-mixed-replace; boundary=frame")


@app.route('/status_feed')
def status_feed():
    def gen():
        while True:
            yield f"data: {current_status}\n\n"
            time.sleep(0.2)

    return Response(gen(), mimetype="text/event-stream")


@app.route('/register_student', methods=["POST"])
def register_student():
    global pending_registration_data, registration_in_progress

    if registration_in_progress:
        return jsonify({"status": "busy"}), 409

    data = request.json
    if data.get("name") and data.get("id"):
        pending_registration_data = data
        return jsonify({"status": "received"}), 200

    return jsonify({"status": "error"}), 400

# ---------------- LOGIC LOOP ----------------
def logic_loop():
    global pending_registration_data, registration_frame_buffer
    global scan_active, registration_in_progress, last_registered_time

    time.sleep(2)
    speak("System online.")

    while True:

        if time.time() - last_registered_time < REGISTER_COOLDOWN:
            time.sleep(1)
            continue

        update_status("WAITING FOR STUDENT")
        scan_active = True

        if current_detected_name is None:
            time.sleep(0.5)
            continue

        # Known
        if current_detected_name != "Unknown":
            speak(f"Hello {current_detected_name.replace('_',' ')}")
            while current_detected_name is not None:
                time.sleep(0.5)
            continue

        # Unknown
        if registration_in_progress:
            continue

        if current_face_count != 1:
            update_status("MULTIPLE OR NO FACES")
            speak("Only one person should stand in front of the camera.")
            time.sleep(2)
            continue

        registration_in_progress = True
        speak("I do not recognize you.")
        speak("Please hold still.")

        frame = get_current_frame()
        if frame is None or current_face_encoding is None:
            registration_in_progress = False
            continue

        if face_encoding_already_registered(current_face_encoding):
            speak("You are already registered.")
            registration_in_progress = False
            continue

        scan_active = False
        registration_frame_buffer = frame

        speak("Please enter your name and ID on the screen.")
        update_status("INPUT REQUIRED")

        timer = 0
        while pending_registration_data is None and timer < 120:
            time.sleep(0.5)
            timer += 1

        if pending_registration_data:
            name = pending_registration_data["name"]
            sid = pending_registration_data["id"]

            if student_id_exists(sid):
                speak("This student ID already exists.")
            else:
                if save_new_student(name, sid, registration_frame_buffer):
                    speak("Registration successful.")
                    last_registered_time = time.time()
                else:
                    speak("Registration failed.")

        pending_registration_data = None
        registration_frame_buffer = None
        registration_in_progress = False
        scan_active = True
        speak("Please step aside.")

# ---------------- VISION LOOP ----------------
def vision_loop():
    global video_frame, current_detected_name
    global current_face_location, current_face_count, current_face_encoding

    # Pi optimized pipeline (RGB â†’ BGR, safe for dlib)
    pipeline = (
        "libcamerasrc ! video/x-raw,width=640,height=480,format=RGB ! "
        "videoconvert ! video/x-raw,format=BGR ! "
        "appsink drop=true max-buffers=1 sync=false"
    )

    cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
    if not cap.isOpened():
        cap = cv2.VideoCapture(0)

    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.05)
            continue

        frame_count += 1

        if scan_active and frame_count % 5 == 0:
            small = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)

            locs = face_recognition.face_locations(rgb, model="hog")
            encs = face_recognition.face_encodings(rgb, locs)

            current_face_count = len(locs)
            current_detected_name = None
            current_face_location = None
            current_face_encoding = None

            if locs:
                loc = locs[0]
                current_face_location = (loc[0]*4, loc[1]*4, loc[2]*4, loc[3]*4)

                enc = np.ascontiguousarray(encs[0])
                current_face_encoding = enc

                name = "Unknown"
                if known_face_encodings:
                    matches = face_recognition.compare_faces(known_face_encodings, enc, tolerance=0.5)
                    dists = face_recognition.face_distance(known_face_encodings, enc)
                    best = np.argmin(dists)
                    if matches[best]:
                        name = known_face_names[best]

                current_detected_name = name

        if current_face_location:
            t, r, b, l = current_face_location
            color = (0, 255, 0) if current_detected_name != "Unknown" else (0, 0, 255)
            cv2.rectangle(frame, (l, t), (r, b), color, 2)

        if current_face_count > 1:
            cv2.putText(frame, "MULTIPLE FACES", (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)

        safe_frame = np.ascontiguousarray(frame.copy())
        with frame_lock:
            video_frame = safe_frame

# ---------------- MAIN ----------------
if __name__ == "__main__":
    load_student_data()
    threading.Thread(target=vision_loop, daemon=True).start()
    threading.Thread(target=logic_loop, daemon=True).start()
    app.run(host="0.0.0.0", port=5000, debug=False, use_reloader=False)
