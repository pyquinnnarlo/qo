# =========================
# register.py â€” REGISTRATION APP (UPDATED)
# Fixes:
# - Clean MJPEG/SSE disconnect handling (no BrokenPipe spam, no GeneratorExit ignored)
# - Speak() now has offline fallback (espeak) + prints audio errors instead of silently failing
# - Safer streaming generators (no bare except that swallows GeneratorExit)
# - threaded=True for Flask
# =========================

import os

# --- Prevent Native Thread Races (dlib/OpenMP/OpenBLAS) ---
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"

import threading
import time
import json
import hashlib
import subprocess
import logging

import cv2
cv2.setNumThreads(1)

import numpy as np
import face_recognition
from flask import Flask, render_template, Response, request, jsonify
from gtts import gTTS

# --- CONFIGURATION ---
app = Flask(__name__)
log = logging.getLogger("werkzeug")
log.setLevel(logging.ERROR)

UNKNOWN_LABEL = "Unknown"
MULTI_LABEL = "MULTIPLE"  # internal label

# --- RECOGNITION TUNING ---
MATCH_THRESHOLD = 0.43
MATCH_MARGIN    = 0.06
CONFIRM_HITS    = 3

# Global Variables
video_frame = None
frame_lock = threading.Lock()
db_lock = threading.Lock()
fr_lock = threading.Lock()

known_face_encodings = []
known_face_names = []   # Name__ID

current_detected_name = None
current_face_location = None
current_face_locations = []
current_face_count = 0
current_status = "SYSTEM READY"

candidate_label = None
candidate_hits = 0

scan_active = True
pending_registration_data = None
registration_frame_buffer = None

# --- DB HELPERS ---
def _read_students_db(json_file="students.json"):
    if not os.path.exists(json_file):
        return {}
    try:
        with open(json_file, "r") as f:
            content = f.read().strip()
            return json.loads(content) if content else {}
    except Exception:
        return {}

def _sanitize_id(student_id: str) -> str:
    sid = str(student_id).strip()
    sid = "".join(ch for ch in sid if ch.isalnum() or ch in ("-", "_"))
    return sid or "UNKNOWN_ID"

def _display_name(label: str) -> str:
    if not label:
        return ""
    return label.split("__")[0] if "__" in label else label

# --- AUDIO (UPDATED) ---
def speak(text: str):
    """
    Plays TTS. Tries gTTS (online) -> mpg123, then falls back to offline espeak.
    Prints errors instead of silently failing.
    """
    global current_status
    print(f"Robot: {text}")

    os.makedirs("audio_cache", exist_ok=True)

    filename = hashlib.md5(text.encode()).hexdigest() + ".mp3"
    mp3_path = os.path.join("audio_cache", filename)

    # 1) Generate MP3 with gTTS (needs internet)
    if not os.path.exists(mp3_path):
        try:
            tts = gTTS(text=text, lang="en", tld="co.uk")
            tts.save(mp3_path)
        except Exception as e:
            print(f" [AUDIO] gTTS failed (internet/DNS?): {e}")
            mp3_path = None

    # 2) Play MP3 if available
    if mp3_path:
        try:
            r = subprocess.run(["mpg123", "-q", mp3_path], timeout=10)
            if r.returncode == 0:
                return
            print(f" [AUDIO] mpg123 return code: {r.returncode}")
        except FileNotFoundError:
            print(" [AUDIO] mpg123 not installed.")
        except Exception as e:
            print(f" [AUDIO] mpg123 failed: {e}")

    # 3) Offline fallback
    try:
        r = subprocess.run(["espeak", text], timeout=10)
        if r.returncode != 0:
            print(f" [AUDIO] espeak return code: {r.returncode}")
    except FileNotFoundError:
        print(" [AUDIO] espeak not installed.")
    except Exception as e:
        print(f" [AUDIO] espeak failed: {e}")

def update_status(status: str):
    global current_status
    current_status = status

# --- DATABASE LOAD ---
def load_student_data():
    print(" [DB] Loading Student Faces...")
    global known_face_encodings, known_face_names
    known_face_encodings = []
    known_face_names = []

    path = "student_pics"
    os.makedirs(path, exist_ok=True)

    for file in os.listdir(path):
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            try:
                img = face_recognition.load_image_file(os.path.join(path, file))
                with fr_lock:
                    encs = face_recognition.face_encodings(img)
                if encs:
                    label = os.path.splitext(file)[0]  # Name__ID
                    known_face_encodings.append(encs[0])
                    known_face_names.append(label)
                    print(f"   + Loaded: {file}")
            except Exception:
                pass

def _best_match_label(new_enc: np.ndarray):
    if not known_face_encodings:
        return None, None, None

    with fr_lock:
        dists = face_recognition.face_distance(known_face_encodings, new_enc)

    if len(dists) == 0:
        return None, None, None

    best_idx = int(np.argmin(dists))
    best_dist = float(dists[best_idx])

    if len(dists) > 1:
        sorted_d = np.sort(dists)
        second_best = float(sorted_d[1])
    else:
        second_best = 999.0

    if (best_dist < MATCH_THRESHOLD) and ((second_best - best_dist) > MATCH_MARGIN):
        return known_face_names[best_idx], best_dist, second_best

    return None, best_dist, second_best

def get_current_frame():
    with frame_lock:
        return video_frame.copy() if video_frame is not None else None

def check_lighting(frame, face_loc):
    if frame is None or face_loc is None:
        return False, 0
    try:
        top, right, bottom, left = face_loc
        h, w, _ = frame.shape
        top = max(0, top); left = max(0, left)
        bottom = min(h, bottom); right = min(w, right)

        face_roi = frame[top:bottom, left:right]
        if face_roi.size == 0:
            return False, 0

        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        avg_brightness = float(np.mean(gray))
        return avg_brightness > 50, avg_brightness
    except Exception:
        return False, 0

def save_new_student(name, student_id, frame):
    try:
        if frame is None:
            return False, "Camera frame missing."

        clean_name = name.strip().replace(" ", "_")
        sid_clean = _sanitize_id(student_id)
        label = f"{clean_name}__{sid_clean}"

        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        with fr_lock:
            locs = face_recognition.face_locations(rgb_frame, number_of_times_to_upsample=0, model="hog")

        if len(locs) != 1:
            return (False, "No face found. Try again.") if len(locs) == 0 else (False, "Multiple faces detected. One student at a time.")

        with fr_lock:
            new_encs = face_recognition.face_encodings(rgb_frame, locs)

        if not new_encs:
            return False, "Face not clear. Try again."
        new_enc = new_encs[0]

        with db_lock:
            json_file = "students.json"
            db = _read_students_db(json_file)

            if sid_clean in db:
                existing_name = db[sid_clean].get("full_name") or db[sid_clean].get("name_key") or "student"
                return False, f"Duplicate blocked: ID already registered for {existing_name}."

            existing_label, _, _ = _best_match_label(new_enc)
            if existing_label is not None:
                existing_display = existing_label.split("__")[0].replace("_", " ")
                return False, f"Duplicate blocked: Face already registered as {existing_display}."

            os.makedirs("student_pics", exist_ok=True)
            img_path = f"student_pics/{label}.jpeg"
            cv2.imwrite(img_path, frame)

            db[sid_clean] = {
                "full_name": name,
                "student_id": sid_clean,
                "name_key": clean_name,
                "image_path": img_path,
                "registered": True,
                "timestamp": time.time()
            }

            with open(json_file, "w") as f:
                json.dump(db, f, indent=4)

            known_face_encodings.append(new_enc)
            known_face_names.append(label)

        return True, "Registration saved."
    except Exception as e:
        print(f" [ERROR] Save failed: {e}")
        return False, "Save failed due to an internal error."

# --- FLASK ROUTES ---
@app.route("/")
def index():
    return render_template("register.html")

@app.route("/video_feed")
def video_feed():
    def generate():
        try:
            while True:
                with frame_lock:
                    frame = video_frame.copy() if video_frame is not None else None

                if frame is None:
                    time.sleep(0.05)
                    continue

                ret, buf = cv2.imencode(".jpg", frame)
                if not ret:
                    time.sleep(0.02)
                    continue

                yield (b"--frame\r\n"
                       b"Content-Type: image/jpeg\r\n\r\n" + buf.tobytes() + b"\r\n")
                time.sleep(0.05)

        except (GeneratorExit, BrokenPipeError, ConnectionResetError):
            return
        except Exception as e:
            print(f" [STREAM ERROR] {e}")
            return

    return Response(generate(), mimetype="multipart/x-mixed-replace; boundary=frame")

@app.route("/status_feed")
def status_feed():
    def generate():
        try:
            while True:
                yield f"data: {current_status}\n\n"
                time.sleep(0.2)
        except (GeneratorExit, BrokenPipeError, ConnectionResetError):
            return
        except Exception as e:
            print(f" [SSE ERROR] {e}")
            return

    return Response(generate(), mimetype="text/event-stream")

@app.route("/register_student", methods=["POST"])
def register_student():
    global pending_registration_data
    data = request.json or {}

    if not data.get("name") or not data.get("id"):
        return jsonify({"status": "error", "message": "Missing name or id"}), 400

    if pending_registration_data is not None:
        return jsonify({"status": "busy", "message": "Registration already pending."}), 409

    pending_registration_data = data
    return jsonify({"status": "received"}), 200

# --- LOGIC LOOP ---
def logic_loop():
    global current_detected_name, pending_registration_data, registration_frame_buffer
    global current_face_location, current_face_count, scan_active

    print(" [LOGIC] logic_loop started")
    time.sleep(2)
    speak("System Online.")

    last_multi_warn = 0

    while True:
        update_status("WAITING FOR STUDENT")
        scan_active = True

        if current_detected_name is None:
            time.sleep(0.5)
            continue

        # MULTI-FACE BLOCK
        if current_detected_name == MULTI_LABEL or current_face_count > 1:
            update_status("MULTIPLE FACES - ONE STUDENT ONLY")
            if time.time() - last_multi_warn > 6:
                speak("Multiple faces detected. One student at a time. Please step back.")
                last_multi_warn = time.time()
            while current_face_count > 1:
                time.sleep(0.5)
            continue

        detected = current_detected_name

        # KNOWN
        if detected != UNKNOWN_LABEL:
            display = _display_name(detected).replace("_", " ")
            update_status(f"WELCOME BACK {display}")
            speak(f"Hello {display}.")
            time.sleep(1)
            while current_detected_name is not None:
                time.sleep(0.5)
            continue

        # NEW
        update_status("NEW STUDENT DETECTED")
        speak("Hello. I do not recognize you.")
        time.sleep(0.5)

        if current_face_count != 1:
            update_status("ONE FACE REQUIRED")
            speak("One student only. Please make sure only one face is in view.")
            while current_face_count != 1:
                time.sleep(0.5)
            continue

        update_status("PREPARING FOR PHOTO")
        speak("Please look directly at the camera.")
        time.sleep(0.5)
        speak("Please remove any hats, glasses, or hair covering your face.")
        time.sleep(3)

        if current_face_count != 1:
            update_status("MULTIPLE FACES - CAPTURE BLOCKED")
            speak("Multiple faces detected. Capture blocked. One student at a time.")
            continue

        frame_snapshot = get_current_frame()
        if frame_snapshot is not None and current_face_location is not None:
            is_bright, _ = check_lighting(frame_snapshot, current_face_location)
            if not is_bright:
                update_status("LIGHTING TOO DARK")
                speak("The lighting is too dark. Please find better light.")
                time.sleep(3)
                continue

        speak("Hold still.")
        time.sleep(1.0)

        registration_frame_buffer = get_current_frame()
        if registration_frame_buffer is None:
            speak("Camera error.")
            continue

        rgb_cap = cv2.cvtColor(registration_frame_buffer, cv2.COLOR_BGR2RGB)
        with fr_lock:
            cap_locs = face_recognition.face_locations(rgb_cap, number_of_times_to_upsample=0, model="hog")

        if len(cap_locs) != 1:
            update_status("CAPTURE INVALID")
            speak("No face found. Please try again.") if len(cap_locs) == 0 else speak("Multiple faces detected. One student at a time.")
            registration_frame_buffer = None
            continue

        speak("Face captured.")
        update_status("CAPTURED - PAUSING VISION")

        scan_active = False
        time.sleep(0.5)

        speak("Please enter your Name and ID on the screen.")
        update_status("INPUT REQUIRED")

        timer = 0
        while pending_registration_data is None:
            time.sleep(0.5)
            timer += 1
            if timer > 120:
                break

        if pending_registration_data:
            name = pending_registration_data["name"]
            sid = pending_registration_data["id"]

            update_status("SAVING...")
            ok, msg = save_new_student(name, sid, registration_frame_buffer)
            if ok:
                update_status("REGISTRATION COMPLETE")
                speak("Registration successful. Thank you.")
            else:
                update_status("REGISTRATION BLOCKED")
                speak(msg)

            pending_registration_data = None
            registration_frame_buffer = None

            scan_active = True
            speak("Please step aside.")
            while current_detected_name is not None:
                time.sleep(1)
        else:
            update_status("TIMEOUT")
            speak("Registration timed out. Resetting.")
            pending_registration_data = None
            registration_frame_buffer = None
            scan_active = True
            time.sleep(2)

# --- VISION LOOP ---
def vision_loop():
    global video_frame, current_detected_name
    global current_face_location, current_face_locations, current_face_count, scan_active
    global candidate_label, candidate_hits

    pipelines = [
        "libcamerasrc ! video/x-raw, width=640, height=480, framerate=15/1, format=YUY2 ! videoconvert ! video/x-raw, format=BGR ! appsink drop=true max-buffers=1 sync=false",
        0
    ]

    cap = None
    for pipeline in pipelines:
        cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER) if isinstance(pipeline, str) else cv2.VideoCapture(pipeline)
        if cap.isOpened():
            break

    if not cap or not cap.isOpened():
        print(" [ERROR] Could not open camera.")
        return

    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue

        frame_count += 1

        if scan_active and frame_count % 10 == 0:
            small = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
            rgb_small = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)

            with fr_lock:
                locs_small = face_recognition.face_locations(rgb_small, number_of_times_to_upsample=0, model="hog")

            current_face_count = len(locs_small)

            if current_face_count > 1:
                current_face_locations = [(t*4, r*4, b*4, l*4) for (t, r, b, l) in locs_small]
                current_face_location = current_face_locations[0] if current_face_locations else None
                current_detected_name = MULTI_LABEL
                candidate_label = None
                candidate_hits = 0

            elif current_face_count == 1:
                (t, r, b, l) = locs_small[0]
                full_loc = (t*4, r*4, b*4, l*4)

                current_face_locations = [full_loc]
                current_face_location = full_loc

                rgb_full = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                with fr_lock:
                    encs_full = face_recognition.face_encodings(rgb_full, [full_loc])

                name = UNKNOWN_LABEL

                if encs_full and known_face_encodings:
                    enc = encs_full[0]
                    label, _, _ = _best_match_label(enc)
                    if label is not None:
                        name = label

                if name == UNKNOWN_LABEL:
                    candidate_label = None
                    candidate_hits = 0
                    current_detected_name = UNKNOWN_LABEL
                else:
                    if candidate_label == name:
                        candidate_hits += 1
                    else:
                        candidate_label = name
                        candidate_hits = 1

                    current_detected_name = name if candidate_hits >= CONFIRM_HITS else UNKNOWN_LABEL

            else:
                current_face_locations = []
                current_face_location = None
                current_detected_name = None
                candidate_label = None
                candidate_hits = 0

        # Draw boxes
        if current_face_locations:
            for (top, right, bottom, left) in current_face_locations:
                if current_face_count > 1 or current_detected_name == MULTI_LABEL:
                    color = (0, 165, 255)
                    label = "MULTIPLE"
                else:
                    color = (0, 255, 0) if current_detected_name not in (None, UNKNOWN_LABEL) else (0, 0, 255)
                    if current_detected_name and current_detected_name not in (UNKNOWN_LABEL, MULTI_LABEL):
                        label = _display_name(str(current_detected_name))
                    elif current_detected_name == UNKNOWN_LABEL:
                        label = UNKNOWN_LABEL
                    else:
                        label = ""

                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
                if label:
                    cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        with frame_lock:
            video_frame = frame.copy()

if __name__ == "__main__":
    load_student_data()
    threading.Thread(target=vision_loop, daemon=True).start()
    threading.Thread(target=logic_loop, daemon=True).start()
    app.run(host="0.0.0.0", port=5000, debug=False, use_reloader=False, threaded=True)
